---
layout: post
title: 阅读cvpr18的论文
---

## [ICLR18有个用gan做one-shot learning的](https://openreview.net/pdf?id=S1Auv-WRZ)
懒得看了

## [one-class classification](https://arxiv.org/pdf/1802.09088.pdf)
用GAN做D区分R(x)和x，然后D作为那个新样本检测器

## [一个新的vqa数据集](https://arxiv.org/abs/1801.08163)

## [Multi-Agent Diverse Generative Adversarial Networks](https://arxiv.org/abs/1704.02906)

## [Multi-Evidence Filtering and Fusion for Multi-Label Classification, Object Detection and Semantic Segmentation Based on Weakly Supervised Learning](https://arxiv.org/abs/1802.09129)
上次组会有人讲了，懒得看了

## [self-contradiction什么的](https://arxiv.org/abs/1604.05132)

## [Learning to Adapt Structured Output Space for Semantic Segmentation](https://arxiv.org/abs/1802.10349)。
用gan做domian adaptationa，看起来有点意思，[gta5dataset](https://download.visinf.tu-darmstadt.de/data/from_games/index.html)

用游戏生成的训练数据(source domian)训练分割模型。因为游戏数据和真实数据的target是相似的，所以在真实数据上测试时用游戏数据的标签作domain adaptation。具体：用D分类预测的标签和游戏数据的标签。

## [net2vec](https://arxiv.org/pdf/1801.03454.pdf)
看不懂懒得看了

## [semi parametric](http://vladlen.info/papers/SIMS.pdf)
此篇引用了我那个只得了70分的本科毕设:)

输入语义分割，输出图片怎么做：对于语义分割里的每个区域，在训练集里检索一个最类似的图片区域，经过训练仿射变换和裁剪，拼凑在一起。（仿射变换和裁剪的模型（模型1）是预训练的）然后再去除拼接的边缘。把拼接的结果输入一个模型，训练这个模型（模型2）弥补边缘。用生成图片和真实图片的感知距离（VGGfeature的L1）距离训练模型2。

## [Visual Dialog with Discriminative Question Generation and Answering](https://arxiv.org/pdf/1803.11186.pdf)

## [vqa memory argumented](https://arxiv.org/abs/1707.04968)

## [single shot finement](https://arxiv.org/abs/1711.06897)

## [dynamic zoom in 大图片](https://arxiv.org/abs/1711.05187)

## [vqa和vqg的对偶](http://cvboy.com/pdf/publications/cvpr2018_iqan.pdf)
本来打算当做开题答辩的思路，突然发现已经被大佬们做过了，，，
